本文介绍通义千问 API 的输入输出参数。

模型介绍、选型建议和使用方法，请参考文本生成。
您可以通过 OpenAI 兼容或 DashScope 的方式调用通义千问 API。

OpenAI 兼容
公有云金融云
使用SDK调用时需配置的base_url：https://dashscope.aliyuncs.com/compatible-mode/v1

使用HTTP方式调用时需配置的endpoint：POST https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions

您需要已获取API Key并配置API Key到环境变量。如果通过OpenAI SDK进行调用，还需要安装SDK。
请求体
文本输入流式输出图像输入视频输入工具调用联网搜索异步调用文档理解文字提取
此处以单轮对话作为示例，您也可以进行多轮对话。
PythonJavaNode.jsGoC#（HTTP）PHP（HTTP）curl
 
import os
from openai import OpenAI

client = OpenAI(
    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key="sk-xxx",
    api_key=os.getenv("DASHSCOPE_API_KEY"), 
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
)
completion = client.chat.completions.create(
    model="qwen-plus", # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
    messages=[
        {'role': 'system', 'content': 'You are a helpful assistant.'},
        {'role': 'user', 'content': '你是谁？'}],
    )
    
print(completion.model_dump_json())
model string （必选）

模型名称。

支持的模型：通义千问大语言模型（商业版、开源版、Qwen-Long）、通义千问VL、通义千问Omni、数学模型、代码模型

通义千问Audio暂不支持OpenAI兼容模式，仅支持DashScope方式。
具体模型名称和计费，请参见模型列表。

messages array （必选）

由历史对话组成的消息列表。

消息类型

System Message object （可选）

模型的目标或角色。如果设置系统消息，请放在messages列表的第一位。

属性

content string （必选）

消息内容。

role string （必选）

固定为system。

User Message object （必选）

用户发送给模型的消息。

属性

content string 或 array （必选）

消息内容。如果您的输入只有文本，则为 string 类型；如果您的输入包含图像等多模态数据，则为 array 类型。

如需传入音频给通义千问Audio模型，请前往DashScope查看，暂不支持使用OpenAI兼容的方式。
使用多模态模型时的属性

role string （必选）

固定为user。

Assistant Message object （可选）

模型对用户消息的回复。

属性

content string （可选）

消息内容。仅当助手消息中指定tool_calls参数时非必选。

role string （必选）

固定为assistant。

partial boolean （可选）

是否开启Partial Mode。使用方法请参考前缀续写（Partial Mode）。

支持的模型

tool_calls array （可选）

在发起 Function Calling后，模型回复的要调用的工具和调用工具时需要的参数。包含一个或多个对象。由上一轮模型响应的tool_calls字段获得。

属性

Tool Message object （可选）

工具的输出信息。

属性

content string （必选）

消息内容，一般为工具函数的输出。

role string （必选）

固定为tool。

tool_call_id string （可选）

发起 Function Calling 后返回的 id，可以通过completion.choices[0].message.tool_calls[0].id获取，用于标记 Tool Message 对应的工具。

stream boolean （可选） 默认值为 false

是否流式输出回复。参数值：

false：模型生成完所有内容后一次性返回结果。

true：边生成边输出，即每生成一部分内容就立即输出一个片段（chunk）。您需要实时地逐个读取这些片段以获得完整的结果。

stream_options object （可选）

当启用流式输出时，可通过将本参数设置为{"include_usage": true}，在输出的最后一行显示所使用的Token数。

如果设置为false，则最后一行不显示使用的Token数。
本参数仅在设置stream为true时生效。

modalities array （可选）默认值为["text"]

输出数据的模态，仅支持 Qwen-Omni 模型指定。可选值：

["text"]：输出文本。

temperature float （可选）

采样温度，控制模型生成文本的多样性。

temperature越高，生成的文本更多样，反之，生成的文本更确定。

取值范围： [0, 2)

由于temperature与top_p均可以控制生成文本的多样性，因此建议您只设置其中一个值。更多说明，请参见Temperature 和 top_p。

temperature默认值

qwen-max系列、qwen-plus系列、qwen-turbo系列以及qwen开源系列、qwen-coder系列：0.7；

qwen-long、qwen-omni-turbo系列：1.0；

qwen-vl-ocr：0.1；

qwen-vl系列：0.01；

qwen-math系列：0

top_p float （可选）

核采样的概率阈值，控制模型生成文本的多样性。

top_p越高，生成的文本更多样。反之，生成的文本更确定。

取值范围：（0,1.0]

由于temperature与top_p均可以控制生成文本的多样性，因此建议您只设置其中一个值。更多说明，请参见Temperature 和 top_p。

top_p默认值

qwen-max系列、qwen-plus系列、qwen-turbo系列、qwen开源系列、qwen-coder系列、qwen-long：0.8；

qwen-vl-ocr、qwen-vl-max-2024-11-19、qwen-vl-max-2024-10-30、qwen-vl-max-2024-08-09、qwen2-vl-72b-instruct、qwen-omni-turbo 系列：0.01；

qwen-vl-max-latest、qwen-vl-max-2024-12-30、qvq-72b-preview、qwen2-vl-2b-instruct、qwen-vl-plus-latest、qwen-vl-plus-0809、qwen-vl-plus-2023-12-01：0.001；

qwen-math系列：1.0；

presence_penalty float （可选）

控制模型生成文本时的内容重复度。

取值范围：[-2.0, 2.0]。正数会减少重复度，负数会增加重复度。

适用场景：

较高的presence_penalty适用于要求多样性、趣味性或创造性的场景，如创意写作或头脑风暴。

较低的presence_penalty适用于要求一致性或专业术语的场景，如技术文档或其他正式文档。

presence_penalty默认值

qwen-max、qwen-max-latest、qwen-max-2024-09-19、qwen-vl-max、qwen-vl-max-latest、qwen-vl-max-2024-12-30、qwen-vl-max-2024-11-19、qwen-vl-max-2024-10-30、qwen-vl-max-2024-08-09、qwen2-vl-72b-instruct：1.5；

其余均为0.0。

原理介绍

示例

response_format object （可选） 默认值为{"type": "text"}

返回内容的格式。可选值：{"type": "text"}或{"type": "json_object"}。设置为{"type": "json_object"}时会输出标准格式的JSON字符串。使用方法请参见：结构化输出（JSON Mode）。

如果指定该参数为{"type": "json_object"}，您需要在System Message或User Message中指引模型输出JSON格式，如：“请按照json格式输出。”
支持的模型

max_tokens integer （可选）

本次请求返回的最大 Token 数。

max_tokens 的设置不会影响大模型的生成过程，如果模型生成的 Token 数超过max_tokens，本次请求会返回截断后的内容。
默认值和最大值都是模型的最大输出长度。关于各模型的最大输出长度，请参见模型列表。

max_tokens参数适用于需要限制字数（如生成摘要、关键词）、控制成本或减少响应时间的场景。

n integer （可选） 默认值为1

生成响应的个数，取值范围是1-4。对于需要生成多个响应的场景（如创意写作、广告文案等），可以设置较大的 n 值。

当前仅支持 qwen-plus 模型，且在传入 tools 参数时固定为1。
设置较大的 n 值不会增加输入 Token 消耗，会增加输出 Token 的消耗。
seed integer （可选）

设置seed参数会使文本生成过程更具有确定性，通常用于使模型每次运行的结果一致。

在每次模型调用时传入相同的seed值（由您指定），并保持其他参数不变，模型将尽可能返回相同的结果。

取值范围：0到231−1。

seed默认值

stop string 或 array （可选）

使用stop参数后，当模型生成的文本即将包含指定的字符串或token_id时，将自动停止生成。

您可以在stop参数中传入敏感词来控制模型的输出。

stop为array类型时，不可以将token_id和字符串同时作为元素输入，比如不可以指定stop为["你好",104307]。
tools array （可选）

可供模型调用的工具数组，可以包含一个或多个工具对象。一次Function Calling流程模型会从中选择一个工具。

目前不支持通义千问VL/Audio，也不建议用于数学和代码模型。
属性

type string （必选）

tools的类型，当前仅支持function。

function object （必选）

属性

name string （必选）

工具函数的名称，必须是字母、数字，可以包含下划线和短划线，最大长度为64。

description string （必选）

工具函数的描述，供模型选择何时以及如何调用工具函数。

parameters object （必选）

工具的参数描述，需要是一个合法的JSON Schema。JSON Schema的描述可以见链接。如果parameters参数为空，表示function没有入参。

tool_choice string 或 object （可选）默认值为 "auto"

如果您希望对于某一类问题，大模型能够采取制定好的工具选择策略（如强制使用某个工具、强制使用至少一个工具、强制不使用工具等），可以通过修改tool_choice参数来强制指定工具调用的策略。可选值：

"auto"

表示由大模型进行工具策略的选择。

"none"

如果您希望无论输入什么问题，Function Calling 都不会进行工具调用，可以设定tool_choice参数为"none"；

{"type": "function", "function": {"name": "the_function_to_call"}}

如果您希望对于某一类问题，Function Calling 能够强制调用某个工具，可以设定tool_choice参数为{"type": "function", "function": {"name": "the_function_to_call"}}，其中the_function_to_call是您指定的工具函数名称。

parallel_tool_calls boolean （可选）默认值为 false

是否开启并行工具调用。参数为true时开启，为false时不开启。并行工具调用详情请参见：并行工具调用。

translation_options object （可选）

当您使用翻译模型时需要配置的翻译参数。

属性

source_lang string （必选）

源语言的英文全称，详情请参见支持的语言。您可以将source_lang设置为"auto"，模型会自动判断输入文本属于哪种语言。

target_lang string （必选）

目标语言的英文全称，详情请参见支持的语言。

terms arrays （可选）

在使用术语干预翻译功能时需要设置的术语数组。

属性

source string （必选）

源语言的术语。

target string （必选）

目标语言的术语。

tm_list arrays （可选）

在使用翻译记忆功能时需要设置的翻译记忆数组。

属性

source string （必选）

源语言的语句。

target string （必选）

目标语言的语句。

domains string （可选）

在使用领域提示功能时需要设置的领域提示语句。

领域提示语句暂时只支持英文。
若您通过Python SDK调用，请通过extra_body配置。配置方式为：extra_body={"translation_options": xxx}。
enable_search boolean （可选）

模型在生成文本时是否使用互联网搜索结果进行参考。取值如下：

true：启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑判断是否使用互联网搜索结果。

如果模型没有搜索互联网，建议优化Prompt，或设置search_options中的forced_search参数开启强制搜索。
false（默认）：关闭互联网搜索。

启用互联网搜索功能可能会增加 Token 的消耗。
若您通过 Python SDK调用，请通过extra_body配置。配置方式为：extra_body={"enable_search": True}。
支持的模型

search_options object （可选）

联网搜索的策略。仅当enable_search为true时生效。

属性

forced_search boolean（可选）默认值为false

是否强制开启搜索。参数值：

true：强制开启；

false：不强制开启。

search_strategy string（可选）默认值为"standard"

搜索互联网信息的数量。参数值：

"standard"：在请求时搜索5条互联网信息；

"pro"：在请求时搜索10条互联网信息。

若您通过 Python SDK调用，请通过extra_body配置。配置方式为：extra_body={"search_options": xxx}。
X-DashScope-DataInspection string （可选）

在通义千问 API 的内容安全能力基础上，是否进一步识别输入输出内容的违规信息。取值如下：

'{"input":"cip","output":"cip"}'：进一步识别；

不设置该参数：不进一步识别。

通过 HTTP 调用时请放入请求头：-H "X-DashScope-DataInspection: {\"input\": \"cip\", \"output\": \"cip\"}"；

通过 Python SDK 调用时请通过extra_headers配置：extra_headers={'X-DashScope-DataInspection': '{"input":"cip","output":"cip"}'}。

详细使用方法请参见内容安全。

不支持通过 Node.js SDK设置。
不适用于 Qwen-VL 系列模型。
chat响应对象（非流式输出）
 
{
    "choices": [
        {
            "message": {
                "role": "assistant",
                "content": "我是阿里云开发的一款超大规模语言模型，我叫通义千问。"
            },
            "finish_reason": "stop",
            "index": 0,
            "logprobs": null
        }
    ],
    "object": "chat.completion",
    "usage": {
        "prompt_tokens": 3019,
        "completion_tokens": 104,
        "total_tokens": 3123,
        "prompt_tokens_details": {
            "cached_tokens": 2048
        }
    },
    "created": 1735120033,
    "system_fingerprint": null,
    "model": "qwen-plus",
    "id": "chatcmpl-6ada9ed2-7f33-9de2-8bb0-78bd4035025a"
}
id string

本次调用的唯一标识符。

choices array

模型生成内容的数组，可以包含一个或多个choices对象。

属性

finish_reason string

有三种情况：

因触发输入参数中的stop条件，或自然停止输出时为stop；

因生成长度过长而结束为length；

因需要调用工具而结束为tool_calls。

index integer

当前响应在choices数组中的序列编号。

logprobs object

该参数当前固定为null。

message object

本次调用模型输出的消息。

属性

created integer

本次chat请求被创建时的时间戳。

model string

本次chat请求使用的模型名称。

object string

始终为chat.completion。

service_tier string

该参数当前固定为null。

system_fingerprint string

该参数当前固定为null。

usage object

本次chat请求使用的 Token 信息。

属性

completion_tokens integer

模型生成回复转换为 Token 后的长度。

prompt_tokens integer

用户的输入转换成 Token 后的长度。

total_tokens integer

prompt_tokens与completion_tokens的总和。

completion_tokens_details object

该参数当前固定为null。

prompt_tokens_details object

输入 Token 的细粒度分类。

属性

audio_tokens integer

该参数当前固定为null。

cached_tokens integer

命中 Cache 的 Token 数。Context Cache 详情请参见上下文缓存（Context Cache）。

chat响应chunk对象（流式输出）
 
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[{"delta":{"content":"","function_call":null,"refusal":null,"role":"assistant","tool_calls":null},"finish_reason":null,"index":0,"logprobs":null}],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":null}
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[{"delta":{"content":"我是","function_call":null,"refusal":null,"role":null,"tool_calls":null},"finish_reason":null,"index":0,"logprobs":null}],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":null}
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[{"delta":{"content":"来自","function_call":null,"refusal":null,"role":null,"tool_calls":null},"finish_reason":null,"index":0,"logprobs":null}],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":null}
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[{"delta":{"content":"阿里","function_call":null,"refusal":null,"role":null,"tool_calls":null},"finish_reason":null,"index":0,"logprobs":null}],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":null}
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[{"delta":{"content":"云的超大规模","function_call":null,"refusal":null,"role":null,"tool_calls":null},"finish_reason":null,"index":0,"logprobs":null}],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":null}
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[{"delta":{"content":"语言模型，我","function_call":null,"refusal":null,"role":null,"tool_calls":null},"finish_reason":null,"index":0,"logprobs":null}],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":null}
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[{"delta":{"content":"叫通义千","function_call":null,"refusal":null,"role":null,"tool_calls":null},"finish_reason":null,"index":0,"logprobs":null}],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":null}
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[{"delta":{"content":"问。","function_call":null,"refusal":null,"role":null,"tool_calls":null},"finish_reason":null,"index":0,"logprobs":null}],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":null}
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[{"delta":{"content":"","function_call":null,"refusal":null,"role":null,"tool_calls":null},"finish_reason":"stop","index":0,"logprobs":null}],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":null}
{"id":"chatcmpl-e30f5ae7-3063-93c4-90fe-beb5f900bd57","choices":[],"created":1735113344,"model":"qwen-plus","object":"chat.completion.chunk","service_tier":null,"system_fingerprint":null,"usage":{"completion_tokens":17,"prompt_tokens":22,"total_tokens":39,"completion_tokens_details":null,"prompt_tokens_details":{"audio_tokens":null,"cached_tokens":0}}}
id string

本次调用的唯一标识符。每个chunk对象有相同的 id。

choices array

模型生成内容的数组，可包含一个或多个choices对象。如果设置include_usage参数为true，则最后一个chunk为空。

属性

delta object

chat请求的增量对象。

属性

content string

chunk的消息内容。

reasoning_content string

QwQ 模型的深度思考内容。

function_call object

该值默认为null，请参考tool_calls参数。

refusal object

该参数当前固定为null。

role string

增量消息对象的角色，只在第一个chunk中有值。

tools_calls array

模型回复的要调用的工具以及调用工具所需的参数。可以包含一个或多个工具响应对象。

属性

index integer

工具信息在tool_calls列表中的索引。

id string

本次工具响应的ID。

function object

需要被调用的函数。

属性

arguments string

需要输入到工具中的参数，所有chunk的arguments拼接后为完整的JSON字符串。

由于大模型响应有一定随机性，输出的JSON字符串并不总满足于您的函数，建议您在将参数输入函数前进行参数的有效性校验。
name string

函数名称，只在第一个chunk中有值。

type string

工具的类型，当前只支持function。

finish_reason string

有四种情况：

因触发输入参数中的stop条件，或自然停止输出时为stop；

当生成未结束时为null；

因生成长度过长而结束为length；

因需要调用工具而结束为tool_calls。

index integer

当前响应在choices列表中的序列编号。当输入参数 n 大于1时，您需要根据 index 参数来进行不同响应对应的完整内容的拼接。

created integer

本次chat请求被创建时的时间戳。每个chunk对象有相同的时间戳。

model string

本次chat请求使用的模型名称。

object string

始终为chat.completion.chunk。

service_tier string

该参数当前固定为null。

system_fingerprintstring

该参数当前固定为null。

usage object

本次chat请求使用的Token信息。只在include_usage为true时，在最后一个chunk显示。

属性

completion_tokens integer

模型生成回复转换为 Token 后的长度。

prompt_tokens integer

用户的输入转换成 Token 后的长度。

total_tokens integer

prompt_tokens与completion_tokens的总和。

completion_tokens_details object

Qwen-Omni 模型输出的文本转换为 Token 后的长度。

属性

text_tokens integer

Qwen-Omni 模型输出的文本转换为 Token 后的长度。

prompt_tokens_details object

输入数据的 Token 细粒度分类。

属性

audio_tokens integer

使用Qwen-Omni 模型时，输入的音频转换为 Token 后的长度。

视频文件中的音频转换为 Token 后的长度会在该参数中体现。
text_tokens integer

使用Qwen-Omni 模型时，输入的文本转换为 Token 后的长度。

video_tokens integer

使用Qwen-Omni 模型时，输入的视频（图片列表形式或视频文件）转换为 Token 后的长度。如果输入的是视频文件，则video_tokens 不包含音频的 Token，音频的 Token 在audio_tokens中体现。

image_tokens integer

使用Qwen-Omni 模型时，输入的图片转换为 Token 后的长度。

cached_tokens integer

命中 Cache 的 Token 数。Context Cache 详情请参见上下文缓存（Context Cache）。

DashScope
公有云金融云
通过HTTP调用时需配置的endpoint：

使用通义千问大语言模型：POST https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation

使用通义千问VL或通义千问Audio模型：POST https://dashscope.aliyuncs.com/api/v1/services/aigc/multimodal-generation/generation

您需要已获取API Key并配置API Key到环境变量。如果通过DashScope SDK进行调用，还需要安装DashScope SDK。
请求体
文本输入流式输出图像输入视频输入音频输入联网搜索工具调用异步调用文字提取
此处以单轮对话作为示例，您也可以进行多轮对话。
PythonJavaPHP（HTTP）Node.js（HTTP）C#（HTTP）Go（HTTP）curl
 
import os
import dashscope

messages = [
    {'role': 'system', 'content': 'You are a helpful assistant.'},
    {'role': 'user', 'content': '你是谁？'}
    ]
response = dashscope.Generation.call(
    # 若没有配置环境变量，请用百炼API Key将下行替换为：api_key="sk-xxx",
    api_key=os.getenv('DASHSCOPE_API_KEY'),
    model="qwen-plus", # 此处以qwen-plus为例，可按需更换模型名称。模型列表：https://help.aliyun.com/zh/model-studio/getting-started/models
    messages=messages,
    result_format='message'
    )
print(response)
model string （必选）

模型名称。

支持的模型：通义千问大语言模型（商业版、开源版、Qwen-Long）、通义千问VL、通义千问Audio、数学模型、代码模型

具体模型名称和计费，请参见模型列表。

messages array （必选）

由历史对话组成的消息列表。

通过HTTP调用时，请将messages 放入 input 对象中。
消息类型

System Message object

模型的目标或角色。如果设置系统消息，请放在messages列表的第一位。

属性

content string （必选）

消息内容。

role string （必选）

固定为system。

User Message object

用户发送给模型的消息。

属性

content string 或 array （必选）

用户消息的内容。如果您的输入只有文本，则为string类型；如果您的输入包含图像等多模态数据，则为array类型。

属性

text string

传入的文本信息。

image string

使用Qwen-VL 模型进行图片理解时，传入的图片文件。可以为图片的URL或本地路径信息。传入本地文件请参考使用本地文件（Base64编码或本地路径）。

示例值：{"image":"https://xxxx.jpeg"}

video array

使用Qwen-VL 模型进行视频理解时，传入的视频文件。您可以通过图片列表传入。

示例值：{"video":["https://xx1.jpg",...,"https://xxn.jpg"]}

如果您需要直接输入视频文件，请提交工单进行申请以及获取使用方式。
fps float （可选）

对于图像列表：表示图像列表是由原视频每隔 1/fps 秒抽取的。

对于视频文件：表示将传入的视频文件每间隔1/fps 秒抽取一张图像，再组合成图像列表后传入模型。

Qwen2.5-VL 系列模型进行视频理解时设置该参数，表示能够使模型理解图像列表之间的时间间隔，具备感知视频的时间信息的能力。

其他通义千问VL模型可在直接传入视频文件时设置该参数，仅表示将视频文件每间隔1/fps 秒抽取一张图像，通过设置fps可决定抽帧的数量，但无法使模型感知时间信息。

Qwen2.5-VL 系列模型列表

与video参数一起使用，取值范围为 (0.1, 10)，默认值为2.0，示例值如下：

图像列表传入：{"video":["https://xx1.jpg",...,"https://xxn.jpg"]，"fps":2}

视频文件传入：{"video": "https://xx1.mp4"，"fps":2}

audio string

模型为音频理解类模型时，是必选参数，如模型为qwen2-audio-instruct等。
使用音频理解功能时，传入的音频文件。

示例值：{"audio":"https://xxx.mp3"}

min_pixels integer （可选）

仅适用于通义千问OCR模型。
输入图像的最小像素。

与image参数一起使用，默认值：3136（28*28*4）,最小值：10*10。

在通义千问VL和OCR模型中，图像转换为Token的规则：每28x28像素对应一个Token。即min_pixels的默认值为4个Token。
使用方法

当输入图像像素在[min_pixels, max_pixels]区间内时，模型会按原图进行识别。

当输入图像像素小于min_pixels时，会将图像按原比例放大，直到总像素高于min_pixels。

当输入图像像素大于max_pixels时，会将图像按原比例缩小，直到总像素低于max_pixels。

max_pixels integer （可选）

仅适用于通义千问OCR模型。
输入图像的最大像素。

与image参数一起使用，默认值：1003520（28*28*1280），最大值：28*28*30000。

在通义千问VL和OCR模型中，图像转换为Token的规则：每28x28像素对应一个Token。即max_pixels的默认值为1280个Token。
使用方法

当输入图像像素在[min_pixels, max_pixels]区间内时，模型会按原图进行识别。

当输入图像像素小于min_pixels时，会将图像按原比例放大，直到总像素高于min_pixels。

当输入图像像素大于max_pixels时，会将图像按原比例缩小，直到总像素低于max_pixels。

role string （必选）

用户消息的角色，固定为user。

Assistant Message object

模型对用户消息的回复。

属性

content string （必选）

助手消息的内容。

role string （必选）

助手消息的角色，固定为assistant。

partial boolean （可选）

是否开启 Partial Mode。使用方法请参考前缀续写（Partial Mode）。

支持的模型

Tool Message object

工具的输出信息。

属性

content string （必选）

工具消息的内容，一般为工具函数的输出。

role string （必选）

工具消息的角色，固定为tool。

tool_call_id string （可选）

发起 Function Calling 后返回的 id，可以通过response.output.choices[0].message.tool_calls[0]["id"]获取，用于标记 Tool Message 对应的工具。

temperature float （可选）

采样温度，控制模型生成文本的多样性。

temperature越高，生成的文本更多样，反之，生成的文本更确定。

取值范围： [0, 2)

通过HTTP调用时，请将 temperature 放入 parameters 对象中。
temperature默认值

qwen-max系列、qwen-plus系列、qwen-turbo系列、qwen开源系列、qwen-audio系列、qwen-coder系列：0.7；

qwen-vl-ocr：0.1；

qwen-vl系列：0.01；

qwen-math系列：0

top_p float （可选）

核采样的概率阈值，控制模型生成文本的多样性。

top_p越高，生成的文本更多样。反之，生成的文本更确定。

取值范围：（0,1.0]。

Java SDK中为topP。通过HTTP调用时，请将 top_p 放入 parameters 对象中。
top_p默认值

qwen-max系列、qwen-plus系列、qwen-turbo系列、qwen开源系列、qwen-coder系列、qwen-long：0.8；

qwen-vl-ocr、qwen-vl-max-2024-11-19、qwen-vl-max-2024-10-30、qwen-vl-max-2024-08-09、qwen2-vl-72b-instruct、qwen-omni-turbo 系列：0.01；

qwen-vl-max-latest、qwen-vl-max-2024-12-30、qvq-72b-preview、qwen2-vl-2b-instruct、qwen-vl-plus-latest、qwen-vl-plus-0809、qwen-vl-plus-2023-12-01：0.001；

qwen-math系列：1.0；

top_k integer （可选）

生成过程中采样候选集的大小。例如，取值为50时，仅将单次生成中得分最高的50个Token组成随机采样的候选集。取值越大，生成的随机性越高；取值越小，生成的确定性越高。取值为None或当top_k大于100时，表示不启用top_k策略，此时仅有top_p策略生效。

取值需要大于或等于0。

qwen-math 系列、qwen-vl 系列默认值为1，其余均为20。

Java SDK中为topK。通过HTTP调用时，请将 top_k 放入 parameters 对象中。
repetition_penalty float （可选）

模型生成时连续序列中的重复度。提高repetition_penalty时可以降低模型生成的重复度，1.0表示不做惩罚。没有严格的取值范围，只要大于0即可。

repetition_penalty默认值

Java SDK中为repetitionPenalty。通过HTTP调用时，请将 repetition_penalty 放入 parameters 对象中。
对于qwen-vl-ocr模型，repetition_penalty 的默认值为1.05，该参数对模型效果影响较大，请勿随意修改。
vl_high_resolution_images boolean （可选）默认值为 false

是否提高输入图片的默认Token上限。输入图片的默认Token上限为1280，配置为true时输入图片的Token上限为16384。

支持的模型

Java SDK不支持设置该参数。通过HTTP调用时，请将 vl_high_resolution_images 放入 parameters 对象中。
presence_penalty float （可选）

控制模型生成文本时的内容重复度。

取值范围：[-2.0, 2.0]。正数会减少重复度，负数会增加重复度。

适用场景：

较高的presence_penalty适用于要求多样性、趣味性或创造性的场景，如创意写作或头脑风暴。

较低的presence_penalty适用于要求一致性或专业术语的场景，如技术文档或其他正式文档。

presence_penalty默认值

原理介绍

示例

Java SDK不支持设置该参数。通过HTTP调用时，请将 presence_penalty 放入 parameters 对象中。
max_tokens integer （可选）

本次请求返回的最大 Token 数。

max_tokens 的设置不会影响大模型的生成过程，如果模型生成的 Token 数超过max_tokens，本次请求会返回截断后的内容。
默认值和最大值都是模型的最大输出长度。关于各模型的最大输出长度，请参见模型列表。

max_tokens参数适用于需要限制字数（如生成摘要、关键词）、控制成本或减少响应时间的场景。

Java SDK中为maxTokens（模型为通义千问VL/OCR/Audio/ASR时，Java SDK中为maxLength，在 2.18.4 版本之后支持也设置为 maxTokens）。通过HTTP调用时，请将 max_tokens 放入 parameters 对象中。
seed integer （可选）

设置seed参数会使文本生成过程更具有确定性，通常用于使模型每次运行的结果一致。

在每次模型调用时传入相同的seed值（由您指定），并保持其他参数不变，模型将尽可能返回相同的结果。

取值范围：0到231−1。

seed默认值

通过HTTP调用时，请将 seed 放入 parameters 对象中。
stream boolean （可选）

是否流式输出回复。参数值：

false（默认值）：模型生成完所有内容后一次性返回结果。

true：边生成边输出，即每生成一部分内容就立即输出一个片段（chunk）。

该参数仅支持Python SDK。通过Java SDK实现流式输出请通过streamCall接口调用；通过HTTP实现流式输出请在Header中指定X-DashScope-SSE为enable。
incremental_output boolean （可选）默认为false（QwQ 模型默认值为 true）

在流式输出模式下是否开启增量输出。参数值：

false：每次输出为当前已经生成的整个序列，最后一次输出为生成的完整结果。

 
I
I like
I like apple
I like apple.
true：增量输出，即后续输出内容不包含已输出的内容。您需要实时地逐个读取这些片段以获得完整的结果。

 
I
like
apple
.
Java SDK中为incrementalOutput。通过HTTP调用时，请将 incremental_output 放入 parameters 对象中。
response_format object （可选） 默认值为{"type": "text"}

返回内容的格式。可选值：{"type": "text"}或{"type": "json_object"}。设置为{"type": "json_object"}时会输出标准格式的JSON字符串。使用方法请参见：结构化输出（JSON Mode）。

如果指定该参数为{"type": "json_object"}，您需要在 System Message 或 User Message 中指引模型输出 JSON 格式，如：“请按照json格式输出。”
不支持通过 Java SDK 设置该参数。通过HTTP调用时，请将 response_format 放入 parameters 对象中。
支持的模型

result_format string （可选） 默认为"text"（QwQ 模型默认值为 "message"）

返回数据的格式。推荐您优先设置为"message"，可以更方便地进行多轮对话。

Java SDK中为resultFormat。通过HTTP调用时，请将 result_format 放入 parameters 对象中。
stop string 或 array （可选）

使用stop参数后，当模型生成的文本即将包含指定的字符串或token_id时，将自动停止生成。

您可以在stop参数中传入敏感词来控制模型的输出。

stop为array类型时，不可以将token_id和字符串同时作为元素输入，比如不可以指定stop为["你好",104307]。
tools array （可选）

可供模型调用的工具数组，可以包含一个或多个工具对象。一次 Function Calling 流程模型会从中选择其中一个工具。使用 tools 时需要同时指定result_format参数为"message"。无论是发起 Function Calling，还是向模型提交工具函数的执行结果，均需设置tools参数。

目前不支持通义千问VL/Audio，也不建议用于数学和代码模型。
属性

type string （必选）

tools的类型，当前仅支持function。

function object （必选）

属性

name string （必选）

工具函数的名称，必须是字母、数字，可以包含下划线和短划线，最大长度为64。

description string （必选）

工具函数的描述，供模型选择何时以及如何调用工具函数。

parameters objcet （必选）

工具的参数描述，需要是一个合法的JSON Schema。JSON Schema的描述可以见链接。如果parameters参数为空，表示function没有入参。

通过HTTP调用时，请将 tools 放入 parameters JSON 对象中。暂时不支持qwen-vl与qwen-audio系列模型。
tool_choice string 或 object （可选）

在使用tools参数时，用于控制模型调用指定工具。有三种取值：

"none"表示不调用工具。tools参数为空时，默认值为"none"。

"auto"表示由模型判断是否调用工具，可能调用也可能不调用。tools参数不为空时，默认值为"auto"。

object结构可以指定模型调用的工具。例如tool_choice={"type": "function", "function": {"name": "user_function"}}。

type只支持指定为"function"。

function

name表示期望被调用的工具名称，例如"get_current_time"。

Java SDK中为toolChoice。通过HTTP调用时，请将 tool_choice 放入 parameters 对象中。
translation_options object （可选）

当您使用翻译模型时需要配置的翻译参数。

属性

source_lang string （必选）

源语言的英文全称，详情请参见支持的语言。您可以将source_lang设置为"auto"，模型会自动判断输入文本属于哪种语言。

target_lang string （必选）

目标语言的英文全称，详情请参见支持的语言。

terms arrays （可选）

在使用术语干预翻译功能时需要设置的术语数组。

属性

source string （必选）

源语言的术语。

target string （必选）

目标语言的术语。

tm_list arrays （可选）

在使用翻译记忆功能时需要设置的翻译记忆数组。

属性

source string （必选）

源语言的语句。

target string （必选）

目标语言的语句。

domains string （可选）

在使用领域提示功能时需要设置的领域提示语句。

领域提示语句暂时只支持英文。
Java SDK 暂不支持配置该参数。通过HTTP调用时，请将 translation_options 放入 parameters 对象中。
enable_search boolean （可选）

模型在生成文本时是否使用互联网搜索结果进行参考。取值如下：

true：启用互联网搜索，模型会将搜索结果作为文本生成过程中的参考信息，但模型会基于其内部逻辑判断是否使用互联网搜索结果。

如果模型没有搜索互联网，建议优化Prompt，或设置search_options中的forced_search参数开启强制搜索。
false（默认）：关闭互联网搜索。

支持的模型

Java SDK中为enableSearch。通过HTTP调用时，请将 enable_search 放入 parameters 对象中。
启用互联网搜索功能可能会增加 Token 的消耗。
search_options object （可选）

联网搜索的策略。仅当enable_search为true时生效。

通过HTTP调用时，请将 search_options 放入 parameters 对象中。Java SDK中为searchOptions。
属性

enable_source boolean（可选）默认值为false

在返回结果中是否展示搜索到的信息。参数值：

true：展示；

false：不展示。

enable_citation boolean（可选）默认值为false

是否开启[1]或[ref_1]样式的角标标注功能。在enable_source为true时生效。参数值：

true：开启；

false：不开启。

citation_format string（可选）默认值为"[<number>]"

角标样式。在enable_citation为true时生效。参数值：

[<number>]：角标形式为[1]；

[ref_<number>]：角标形式为[ref_1]。

forced_search boolean（可选）默认值为false

是否强制开启搜索。参数值：

true：强制开启；

false：不强制开启。

search_strategy string（可选）默认值为"standard"

搜索互联网信息的数量。参数值：

standard：在请求时搜索5条互联网信息；

pro：在请求时搜索10条互联网信息。

X-DashScope-DataInspection string （可选）

在通义千问 API 的内容安全能力基础上，是否进一步识别输入输出内容的违规信息。取值如下：

'{"input":"cip","output":"cip"}'：进一步识别；

不设置该参数：不进一步识别。

通过 HTTP 调用时请放入请求头：-H "X-DashScope-DataInspection: {\"input\": \"cip\", \"output\": \"cip\"}"；

通过 Python SDK 调用时请通过headers配置：headers={'X-DashScope-DataInspection': '{"input":"cip","output":"cip"}'}。

详细使用方法请参见内容安全。

不支持通过 Java SDK 设置。
不适用于 Qwen-VL、Qwen-Audio 系列模型。
chat响应对象（流式与非流式输出格式一致）
 
{
  "status_code": 200,
  "request_id": "902fee3b-f7f0-9a8c-96a1-6b4ea25af114",
  "code": "",
  "message": "",
  "output": {
    "text": null,
    "finish_reason": null,
    "choices": [
      {
        "finish_reason": "stop",
        "message": {
          "role": "assistant",
          "content": "我是阿里云开发的一款超大规模语言模型，我叫通义千问。"
        }
      }
    ]
  },
  "usage": {
    "input_tokens": 22,
    "output_tokens": 17,
    "total_tokens": 39
  }
}
status_code string

本次请求的状态码。200 表示请求成功，否则表示请求失败。

Java SDK不会返回该参数。调用失败会抛出异常，异常信息为status_code和message的内容。
request_id string

本次调用的唯一标识符。

Java SDK返回参数为requestId。
code string

错误码，调用成功时为空值。

只有Python SDK返回该参数。
output object

调用结果信息。

属性

text string

模型生成的回复。当设置输入参数result_format为text时将回复内容返回到该字段。

finish_reason string

当设置输入参数result_format为text时该参数不为空。

有四种情况：

正在生成时为null；

因模型输出自然结束，或触发输入参数中的stop条件而结束时为stop；

因生成长度过长而结束为length；

因发生工具调用为tool_calls。

choices array

模型的输出信息。当result_format为message时返回choices参数。

属性

finish_reason string

有四种情况：

正在生成时为null；

因模型输出自然结束，或触发输入参数中的stop条件而结束时为stop；

因生成长度过长而结束为length；

因发生工具调用为tool_calls。

message object

模型输出的消息对象。

属性

role string

输出消息的角色，固定为assistant。

content string或array

输出消息的内容。当使用qwen-vl或qwen-audio系列模型时为array，其余情况为string。

如果发起Function Calling，则该值为空。
属性

text string

当使用qwen-vl或qwen-audio系列模型时，输出消息的内容。

reasoning_content string

QwQ 模型的深度思考内容。

tool_calls array

如果模型需要调用工具，则会生成tool_calls参数。

属性

function object

调用工具的名称，以及输入参数。

属性

name string

调用工具的名称

arguments string

需要输入到工具中的参数，为JSON字符串。

由于大模型响应有一定随机性，输出的JSON字符串并不总满足于您的函数，建议您在将参数输入函数前进行参数的有效性校验。
index integer

当前tool_calls对象在tool_calls数组中的索引。

id string

本次工具响应的ID。

type string

工具类型，固定为function。

search_info object

联网搜索到的信息，在设置search_options参数后会返回该参数。

属性

search_results array

联网搜索到的结果。

属性

site_name string

搜索结果来源的网站名称。

icon string

来源网站的图标URL，如果没有图标则为空字符串。

index integer

搜索结果的序号，表示该搜索结果在search_results中的索引。

title string

搜索结果的标题。

url string

搜索结果的链接地址。

usage map

本次chat请求使用的token信息。

属性

input_tokens integer

用户输入内容转换成token后的长度。

output_tokens integer

chat请求返回内容转换成token后的长度。

total_tokens integer

当输入为纯文本时返回该字段，为input_tokens与output_tokens之和。

image_tokens integer

输入内容包含image时返回该字段。为用户输入图片内容转换成token后的长度。

video_tokens integer

输入内容包含video时返回该字段。为用户输入视频内容转换成token后的长度。

audio_tokens integer

输入内容包含audio时返回该字段。为用户输入音频内容转换成token后的长度。

prompt_tokens_details object

输入 Token 的细粒度分类。

属性

cached_tokens integer

命中 Cache 的 Token 数。Context Cache 详情请参见上下文缓存（Context Cache）。